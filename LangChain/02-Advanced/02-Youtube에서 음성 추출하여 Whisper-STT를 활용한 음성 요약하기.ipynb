{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytubefix in /opt/anaconda3/envs/whisper/lib/python3.12/site-packages (6.12.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install pytubefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube에서 오디오 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytubefix import YouTube\n",
    "\n",
    "def downloadYouTube(videourl, path):\n",
    "    yt = YouTube(videourl)\n",
    "    yt = yt.streams.filter(only_audio=True).first()\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return yt.download(path)\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=isUudT58Xfk\"\n",
    "audio_filename = downloadYouTube(url, \"audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로컬에서 파일 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_filename = \"../../Assets/audio/2024-08-21 10-33-51.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### colab에서 파일 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "audio_filename = '/content/drive/MyDrive/OH_MY_GIRL_CLOSER.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API 이용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력할 수 있는 최대 파일 크기는 25 MB이며 입력 파일의 형식은 mp3, mp4, mpeg, mpga, m4a, wav, webm 형식을 지원합니다. 파일 크기가 크다면 pydub 등을 이용해 잘라서 사용하면 됩니다.\n",
    "\n",
    "response_format은 text외에도 `json, verbose_json, srt, vtt` 형식을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "with open(audio_filename, \"rb\") as audio_file:\n",
    "    transcript = client.audio.transcripitons.create(\n",
    "        file = audio_file,\n",
    "        model = \"whisper-1\",\n",
    "        response_format=\"text\",\n",
    "        language=\"ko\",\n",
    "    )\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper Open Source 이용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ffmpeg 설치하기\n",
    "\n",
    "\\# on Ubuntu or Debian\n",
    "\n",
    "`sudo apt update && sudo apt install ffmpeg`\n",
    "\n",
    "\\# on MacOS using Homebrew\n",
    "\n",
    "`brew install ffmpeg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/anaconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/openai/whisper.git -q\n",
    "%pip install torch tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 잘 보입니다 안녕하세요 안녕하세요 김정은이 형 지금 내 머리 보고 웃는 거 아니야? 아니에요 베트남 헤어스타일인가 보네요 요즘 아무 생각 없이 신경 안 써서 베트남 미용실 가서 머리 깎아줘 눈 감고 눈 떴더니 이렇게 돼 있더라고 참아라 보기 싫어도 어쩔 수 없다 제가 이 세면이랑 내가 얘기할 내용은 매일 업무 지연 내역이랑 소수 관리 내역이랑 업데이트 진행 내역이 세 가지가 주제인데 매일 업무 지연 내역에서 지금 진행하는 내용들을 내가 어느 정도 모니터링을 해서 보고는 있는데 이게 파악된 내용들을 이제 앞으로 케이스 형태로 작성해도 되고 아니면 문서 형태로 작성해도 되고 히스터리로 계속 남기면서 그 내용들을 확인을 하고 김정은 부장 그 내용들을 보면서 잘못된 부분들에 있으면 코멘트를 하고 정리를 하고 업데이트를 하는 방식으로 이렇게 진행해야 될 것 같다는 생각은 좀 들어 어떻게 해야 될지는 지금 여기 실무자 분들이 그 부분을 잘 정리해 가지고 가장 좋은 방안을 만들어야 될 거라고 생각을 하고 있고 그리고 9월 달부터는 이제 문형 메인 터너스 정도 수준에서는 일을 한 건씩이라도 한 번씩 테스트를 하면서 업무 지연을 해보고 그 외에 서비스 지원권이나 내용들을 보니까 도대체 이걸 이렇게까지 논의를 해야 될 내용들이냐 라는 것들도 꽤 많이 보이는데 그런 것들은 또 어떤 식으로 업무 지연을 해야 되는지 아니면 누가 업무를 처리해야 되는지 이런 것들도 좀 분류를 해야 되지 않겠나 이런 생각이 좀 들어 기본적으로 메일 대화방을 보니까 어제 건으로 예를 들어서 메일을 발송하는 어떤 프로그램의 우리를 우리한테 얘기를 하고 그거를 지원하는 자법적으로는 확실히 대처를 안 하니까 거기 대화방에 메세지만 한 30건이 왔다 갔다 하더라고 그걸로 그거 실제적으로 피로도가 높아지지 않아? 그런 내용들 있으면? 다른 프로그램이랑 겹치면 그런 일이 발생하는데요 아웃룩이나 이런 거는 냅두더라도 다른 회사에서 만든 그룹에가 있고 우리가 만든 그룹에가 있고 그렇게 되면 이 회사와 우리 회사 간 알력이 생깁니다 중간에 우리 고객사가 있고 어제 같은 건에서 케이스로 보면 그거 같은 경우는 우선 내가 만약에 고객이랑 상담하면 그 자리에서 끝날 내용들이거든요 그거는 절대 저거 문제점은 그쪽에서 폐지를 해라 내용까지도 내 스스로 다 전달하고 그렇게 업무가 끝나야 될 그런 내용들이 사실 보니까 한 50%가 되는 것 같아 매일 대화방 지원 내용에 보면 거기에 보면 실제로 MX 정보가 잘못되어 있는 것들 이런 것들은 몇 가지 케이스로 하기만 하면 맨 처음에 고객 지원을 요청받은 직원분들이 전부 다 처리할 수 있어야 그 내용들이 지금 내일 고객 지원 대화방에 너무 많이 올라오고 있다는 부분들이 조금 문제점이지 않을까 하는 생각도 들기는 하는데 또 그거를 보면서 이런 것까지 직원이 제대로 안 되는구나 라는 내용을 알고 있는 것도 중요한 부분이라고 생각도 들기도 하고 여러 가지 생각이 들어서 내가 의견을 지금 아무 얘기도 안 하고 있는 상황이긴 한데 이게 참 고민이더라고 그런데 그렇다고 해서 지금 저기서 이런 것들은 지원팀에서 학습해서 알아서 하라고 하면 또 한 3개월 뒤에는 또 잘못된 식으로 업무가 진행될 거라고 지금 보일 수도 있고 그런 내용들이 있어가지고 나도 지금 뭔가 규칙을 만들지는 못하고 있어 그런데 그런 부분들은 지금 여기 지금 세 분이서 조금 정의를 해놨면서 대화방에 보면 꼭 지원해야 될 꼭 확인해야 될 내용들이 거의 그 위로 올라가 버리고 그 부분들이 좀 자꾸 패스가 되는 그런 부분들이 생기는 것도 몇 번 봤고 그런 것들을 어떻게 해야 될지 좀 고민을 해봐야 될 것 같아요 이 세 분이서 보면 그래서 그 대화방 내용을 보면서 거의 그 메시지의 50%를 없앨 수 있는 건데 그 메시지의 50%가 서로 간의 업무 진행시에 아니면 내가 뭔가를 개발할 때 그게 마이너스 요소가 되지 않을까 하는 우려점을 가지고 있어 지금 내가 그런 부분들이 좀 있지? 그 부분들은 개선을 해야 될 거라고 봐 어제도 내가 보면서 이 부분은 더 이상 논의 대상이 아니고 이렇게 이렇게 처리하고 이렇게 이렇게 해라 라고 내가 메시지 보내려다가 또 안 보낸 이유가 직원분들이 이 정도까지도 지연이 안 되는 부분이 있다라는 걸 파악해야 되는 것도 중요한 부분이기도 할 거다 또 이런 생각도 들고 좀 고민이 많이 되는 부분들이 있습니다 이 내용들에서 그래서 그거는 조금 그 세 분이서 좀 잘 정리하고 그리고 매일 관련해서 지금 김봉학 부장이랑 신상후부장이 계속적으로 파악하고 있는 내용들은 계속 문서를 유지하는 게 가장 중요한 거고 이게 단편적으로 파악한 내용들이나 이런 것들이 사실 한 6개월 이후에 내가 이런 것들을 파악이도 안 했다 이런 것들이 또 다 물합되고 그때 뭘 했는지도 기억이 안 나고 이런 상황들이 발생하는 이런 형태의 우리 업무 습관을 벌일 수 있도록 항상 문서나 이런 것들을 정확하게 계속적으로 유지를 해가지고 그 이후에도 그 내용들을 다시 파악하거나 또 다시 점검을 하거나 또 기억이 가물가물해서 이걸로 확인이 안 된다거나 이런 형태의 업무 방식이나 업무 습관을 없앨 수 있도록 문서 유지를 잘할 수 있도록 좀 정리를 해주세요 매일 관련해서는 세 분이서 지금 내가 얘기했던 우리 학전들을 지금 얘기를 했던 거고 다음 달부터는 나는 케이스별로 조금 업무 지원을 할 때 지금 아까 얘기했던 그런 이게 김봉학 부장이나 신상후부장이 참여해가지고 뭔가를 케이스별로 운영 유지할 수 있는 정도 수준의 레벨에 것만 지원을 하고 지금 거기 나오는 내용들 중에 조금 서비스 레벨에서 처리할 수 있는 내용들은 좀 구두로 좀 학습을 시켜야 될 부분들이 있지 않겠느냐 업무 지원 직원분들한테 약간씩은 학습을 시켜야 되는 부분이 있지 않겠느냐 그리고 업무 지원 하시는 분들도 그런 것들을 케이스로 잘 유지를 해가지고 이런 상황에서 이런 케이스가 있었고 고객한테 이런 내용이 있었고 이런 것들을 케이스를 잘 정리하라고 하고 그걸 계속적으로 반복해서 보면 반복해서 질문이 안 나와야 될 것들 조차도 계속적으로 나오는 부분들이 있고 예전에 김재현 부장이 얘기했던 것처럼 CID에 .com이 있었을 때 이거를 실행파일로 여벼서 지금 바운스를 한다거나 이런 것들 아니면 헤더의 중복 가장 중요한 헤더 킷밥이 중복되거나 이런 것들은 그냥 보면 알 수 있는 것들인데 이런 거를 그냥 무조건 질문으로 지금 올라오고 있는 거 이런 것들도 우리는 좀 개선해야 될 부분이라고 지금 보인다 그래서 우선 나도 매일 대화방은 계속적으로 좀 보면서 거기서 추출해서 계속적으로 반복해서 오지 않아야 될 것들에 대해서는 조금 뭔가 시스템을 만들어서 업무 지원하는 1차 지원자들이 거기서 끝낼 수 있게 그런 스마트한 방식의 업무 플로어를 만들어 줘야 된다 그런 생각도 좀 들어요. 예전에 김재현 부장이 얘기했던 그 내용이 지금 매일 대화방을 보니까 내가 좀 이해가 돼 이게 단순한 건데 업무 지원이 잘못되어서 어떤 업무가 굉장히 고객한테 잘못 전달되고 이런 부분들이 눈에 많이 보이는 부분이 있어요 매일 관련해서 지연내역은 이 정도로 내가 좀 느꼈던 내용들 전달했고 그리고 소수 관리 내역에서 보면 이걸 앞으로 김재현 부장도 이 소수관리 이 세 분이 같이 참여해가지고 계속 관리하고 메인터너스는 같이 이 세 분이서 나랑 계속 이런 것들을 세 가지 주제를 계속 논의할 수 있도록 하고 여기에 그 한마디로 이거를 확인을 하고 있는 거지 이게 최종적으로 커밋이 됐다 정도 수준으로 해서 확인을 하고 있는 거지 그리고 이게 업데이트 시스템에 연결이 꼭 돼서 여기서 업데이트를 하라는 내용이 사실은 확인이 안 되더라도 그게 당연히 업데이트 주기마다 업데이트가 되려고 하면 소스는 항상 최신 상태에서 유지가 되어야 되기 때문에 그 전제적권을 가지기 때문에 업데이트 소스를 여기다 무조건 연결해서 업데이트 시스템을 만들어라 하는 이유가 그런 이유고 그런 부분에 대해서는 확실히 명시적으로 인지를 하고 있는 거지 지금 마지막으로 업데이트 관련해서 내가 조금 요즘 좀 문제점이 있는 게 그 베트남 직원분들이랑 얘기하고 그랬는데 지금 업데이트가 중기된 상태에서 각각의 좀 간헐적으로 나오는 문제점들이 지금 발생하고 있는데 업데이트 일자로 조금 더 앞당길 수 있는 방법은 없나? 업데이트를 하려고 하면은 당길 수는 있는데 이제 저희가 지난번 업데이트 문제가 생긴 이후로 이제 추후에 업데이트 하기 전에 무조건 고객한테 공지를 한다 이게 일단 들어갔고요. 공지 내용에는 이번 업데이트의 변경점이 뭐다 이런 걸 포함해서 보낼 것이기 때문에 업데이트 하기 전에 사전 준비하는 작업이 필요합니다 업데이트 변경점 정리하고 한글로 번역하고 그게 업데이트 될 서버로 고객들한테 공지 메일 보내고 그리고 한 일주일 정도 있다가 업데이트하고 이런 식으로 진행이 되기 때문에 한 3주 정도는 필요합니다. 업데이트 하기 전에 나는 업데이트 실전에서 지금 이런 행정적인 절차나 이런 부분에 대해서는 사실 크게 관여를 하고 싶지 않아. 그거는 현재 운영했던 분들이 어떤 부분에 문제점이 있을 거라는 걸 잘 알고 있으니까 내가 가장 중요한 점으로 보는 거는 업데이트의 실제적으로 테크닉 라서야 되니까 업데이트를 진행할 때 어떤 부분을 업데이트하고 어떻게 체크를 하고 어떤 문제점들을 이슈 리스트를 다 점검을 하고 그리고 최종적으로 업데이트가 완료됐다는 그 시점까지 그것들을 정확하게 업데이트 프로세서를 만들어주는 게 더 중요하다고 생각을 하는 거고 그 앞에 어떤 행정처리나 이런 것들에 대해서는 그거는 조금 더 계략적으로 단순화 시켜가지고 업무를 진행할 수 있게 하고 사실 지금 업데이트가 중지되가지고 모바일 앱도 지금 계속 오류가 나오고 있는 고객들이 지금 발생하고 이런 것들은 서비스 품질 저하에 굉장히 영향을 미치는 부분들이기 때문에 무조건 업데이트라는 관점에서 여기서 문제점이 안 일어나야지 라는 건 당연히 중요한데 업데이트가 이런 식으로 행정처리나 아니면 업무처리 절차에 의해서 계속적으로 지연되서 서비스에 오륜 것 발생하는 부분도 그것도 어느 정도 우리가 보료를 해서 판단을 해서 업데이트를 어떤 식으로 해야 될지에 대해서 조금 더 생각을 해봐야 된다는 문제점이 있는 거지 지금 단순하게 생각하면 안 돼. 지금 보면 업데이트를 무조건 이루어져야 되고 진행이 돼야 되는데 그런데 업데이트를 했을 때 고객한테 책임을 지우지 않으면 우리가 책임이 없게만큼 모든 것들을 다 공지하고 했다고 하더라도 어차피 고객은 모르는 고객은 몰라 관심 없는 고객은 뭐가 어떻게 되는지도 몰라. 지금 얘기하는 내용들은 사실 한비로 내에서 이렇게까지 해야지 고객이 알 거 아니냐고 얘기를 하지만 고객이 90%는 이렇게 바꾼다고 하는데 그거에 대해서 정확하게 인지를 못한다는 얘기지. 그런 부분들까지도 고민해서 업데이트를 해야 되는 거고 그래서 업데이트를 지금 너무 지연이 되는 부분이 서비스의 품질에 저하가 일어나는 부분이 발생할 거라고 하면 그런 부분은 개선을 해야 되는 거지 지금 인지 알겠어요 지금 아까 신상호 부장이 얘기했던 것처럼 업데이트를 시에 일주일 전에 공지하고 그리고 내용들 전부 다 취합해서 내용들 전부 다 공지 내용들 전부 다 취합해서 넣고 그러고 난 다음에 업데이트를 진행하고 그랬을 때 그 이전에 사전 준비에 대한 내용에 대해서 고객한테 알려준다고 하는데 이전과 지금이 고객이 훨씬 더 많은 것들에 대해서 인지를 하고 있을 거냐 나는 그렇지 않다고 고객이 크레임이 걸려온 부분 중에 하나가 그 부분이었으니까요. 니네는 업데이트를 하는데 뭘 업데이트 하는지 얘기도 안 하고 하느냐 이게 몇 군데에서 나왔거든요 사실 그 크레임이 걸리는 가장 주요 사안들은 문제가 발생했기 때문이에요 그래서 그 부분도 같이 개선을 하고 있습니다. 업데이트 하고 있습니다 지금 무슨 내용인지는 알겠는데 내가 얘기했던 내용도 하나의 관점으로 보라는 얘기지 그 고객한테 컴플레인이 나왔던 모든 지금 얘기했던 그런 컴플레인이 나왔던 고객들은 그 고객의 업데이트 이후에 문제점들이 발생했기 때문에 컴플레인을 계속 추가를 하는 거지 업데이트가 정상적으로 잘 됐고 새로운 게 뭐가 보이네 라고 했을 때 고객은 이게 뭐예요 라고 묻지 어떤 기능인지 이거 좀 설명해주세요 라고 이런식의 질문을 하지 그걸로 크레임을 걸지는 않는다고 하죠. 그래서 가장 중요한 문제점은 업데이트 이후에 문제점이 발생했기 때문이기 때문에 그 문제점이 발생하지 않게 만드는 게 가장 포인트라는 거지 그래서 내가 그때 얘기했던 게 업데이트 이후에 나왔던 문제점들이 무엇인지 항상 리스터블을 하고 업체별로라도 리스트를 하고 그거를 업데이트 이후에 나오지 않도록 그거를 전부 다 점검하고 난 다음에 업데이트를 해라 라고 하는 것들이 반복되지 않기 때문에 반복되지 않게 하는 게 가장 중요한 부분이라는 거고 그런 포인트들을 잘 집어서 업무 진행할 때 그 포인트만 개선을 하는 게 가장 중요한 지점이라는 거고 모든 것들이 다 행정적으로 이걸 맞게 1부터 0부터 10까지 맞게 하겠다라는 것보다 무엇이 문제였는지 그것만 집어서 그것만 개선하는 게 우리한테 가장 중요한 부분이라는 거지 그래서 업데이트 관련해서도 지금 조금 더 생각을 해서 고객들한테 계속 질문이 나오고 어떤 서버에 단편적으로 바로바로 업데이트를 하고 어떤 고객들은 그 불편상을 가지고 있을 수도 있고 그렇기 때문에 그런 것들을 간과하지 말고 어떻게 해야 될지에 좀 더 고민을 해서 업데이트 프로세스를 잘 정립을 하는 게 있겠습니다. 내가 뭐 어떻게 어떻게 하고 이건 이렇게 하고 며칠을 하고 이렇게까지 정해주지는 못해. 그런데 지금 내용들에 대해서 내가 조금 더 내가 고민하고 생각했던 내용들에 대해서 한번 정리하는 거예요. 이 세 가지 주제로 앞으로 우리 세 분은 화요일 날 계속적으로 회의를 하면서 업무를 진행하고 그리고 이제 그 내용들을 다 포함해서 김정인 부장도 소수 관리 툴이나 이런 것들을 다 포함시켜서 이 세 가지 주제는 이 세 분이 나랑 계속적으로 좀 주요한 업무 내용으로 좀 확인하면서 개선하고 진행하시도록 그렇게 정리를 해보죠. 네. 내가 의견 전달한 거는 어느 정도 잘 전달이 됐지? 네. 이미 그렇게 계획을 하고 있는데 이걸 조금씩 조금씩 진행을 하다 보니까 결과가 빨리 안 나오는 부분이 있고요. 근데 사실 좀 굉장히 중요한 부분이야 지금 현재 상황에서는. 그래서 이 부분을 내가 좀 더 강조한 거고 그래서 빠르게 방안을 마련해서 업무를 진행할 수 있도록 그렇게 베트남 쪽에서도 많이 준비할 내용이나 아니면 업무 대기할 사람이 필요하다 그러면 전부 다 일찍 잡아서 대기시키고 그렇게 업무를 진행해 줄 것 같아. 네. 그리고 김정인 부장 어제 제가 잠깐 얘기했던 아웃루어 관련해서 메일 그냥 맥룡 기본 클라이언트에서 보니까 현재 활성화된 상태에서 예외 메일함을 수정, 삭제했는데 적용이 안 되는 것 같고 비활성화해서 저장하고 다시 활성화해서 예외 메일함을 재설정을 하고 저장을 하니까 동작을 하는 것 같아. 그 정도 내용이 중요한 건 아니야. 내가 봤을 때는 활성화된 상태에서 예외 메일함을 뭔가를 수정을 했을 때 그 업데이트가 안 된 게 아닌가 라는 정도 의심만 하고 있고 그것만 한번 체크해 보면 될 것 같아. 그게 크게 중요한 건 아니고. 그리고 마지막으로 아임에보면 확실히 많이 느리네. 느릴 수 밖에 없죠. 많이 느린 편이긴 하네. 자, 그럼 내가 팝3를 테스트할까? 아임에보면 계속 테스트를 하고 있을까? 일단 아임에보는 새로 개발할 사항이고요. 팝3는 새로 개발이 얼추 완료가 됐습니다. 그럼 팝3 테스트 진행을 하고? 예. 예. 엔저만비로에 적용을 했고요. 일단 해주시면 좋긴 한데 저희가 이제 제가 쪽지에도 보냈다시피 테스트를 해야 될 사항이 서버 부하 테스트를 해야 돼요. 그러니까 동시에 많이 접근을 해야 되는데 지금 그거 테스트가 안 되고 있어서 어떻게 할까 고민 중입니다. 때려줄까? K6 같은 걸로 내가 서버에 때려줄까? 그것보다는 많은 유저가 한 번에 붙어야 되거든요. 정상적인 유저가 정상적인 호출을 요청한 거고 나처럼 때리지 말라? 아니 뭐 때리셔도 상관없습니다. 때려보는 것도 괜찮긴 한다 하면 내가 때려줄게. 그러면 쪽지를 보낼 때 테스트를 해 주세요 이렇게 보냈잖아요. 그러지 말고 아예 몇 시 몇 분에 공식 해달라고 하잖아요. 그 시간에 다 붙을 테니까. 제가 우리 거 회사에 있는 아웃루 버전을 조사를 해봤는데 종류별로 다 있어요. 그러니까 그 종류별로 어떻게 나올지도 궁금하기도 하고. 왜 어떤 버전은 되는데 어떤 버전은 안 될 수도 있잖아요. 그런 것도 테스트가 필요한데 제가 지금 우려하는 거는 뭐냐면 이게 구로 만들어서 동시에 접근하면 빨라졌잖아요. 그런데 서버 부하가 없을 수가 없거든요. 그러니까 메모리는 현재까지는 괜찮은데 동시에 접근하면 어떻게 될지 궁금하기도 하고. 그다음에 많이 가져가면 서버 부하가 어느 정도 올라가는지 그것도 좀 궁금하기도 하고. 그런 게 테스트가 돼야 그게 고객한테 적용이 됐을 때 우리한테 리스크가 훨씬 적게 다가오고 싶거든요. 이게 필요한데. 그러니까 제가 말하는 거는 쪽지를 보낼 때 테스트 시간을 기재를 해가지고 8월 몇 시에 테스트해 주세요 이렇게 하면 다들 그때부터 다 할 생각입니다. 개별적으로 하게 되면 별로 효과가 없다. 테스트해 주세요 하면 오늘 하든가 내일 하든가 뭐 시간 날 때 하지 이렇게 생각을 할 건데 시간을 지정해서 이때 테스트해 주세요 하면 다들 그때 테스트하지 않겠냐. 그러면 다시 공지해서 시간 중에 다. 제발 공지하는 것 보다. 세 분이서 다시 얘기해서 전 직원들 다 공시에 사용하라고 다 얘기를 해. 그걸 굳이 뭐 전문인 지시사항이다 아니면 내 지시사항이다 얘기할 필요 없이. 세 분이서 전 직원 전부 다 없는 클라이언트 동시에 사용 그룹이랑 같이 사용해달라. 그렇게 얘기를 해. 나도 지금 바로 메일 한 번 한 5개 넣어가지고 바로 팝3도 연결해가지고 테스트 진행할 테니까 나머지 분들 전부 다 테스트 진행할 수 있도록 그렇게 전부 다 공지를 해줘. 알겠습니다. 특별히 나한테 또 따로 요청사항이나 얘기할 내용들 있나요? 없습니다. 지금 나랑 회의 전에 아마 회의를 해내지 않았는지 모르겠는데 우리 세 명은 내가 의미한테 전달한 내용들을 가지고 가볍게 한번 설명해 주셔서 조금 더 신무적인 논의를 한번 해봤으면 좋겠다는 생각이 들고 한번 논의해 봐. 네 알겠습니다. 수고 좀 해주세요. 그러면 공지 좀 해주셨을까요? 내가 할게. 알겠습니다. 몇 시가 좋으려나 업무가 좀 그래도 한가한 시간대가 좋을 것 같긴 한데. 점심 먹고 밥 먹고. 저도 밥 먹고 와가지고. 그러면 1시에서 2시? 1시에서 2시 사이에 붙어라. 그럼 지금 11시인가 지금 공지하지 뭐 그러면. 알겠습니다. 1시에서 2시 사이 1시간. 그때 테스트 한번 하고. 근데 아웃룩이 있나 근데? 아웃룩이 버전별로 있어요. 2007부터 시작해서. 있는 사람 있고 없는 사람 있고. 아 근데 이게. 없는 사람은 썬더버드로. 네 썬더버드나 다른 메이클라이언트에 받아서. 나는 썬더버드로 설치해서 했는데 혹시라도 아웃룩을 안 쓰는 사람들이 있을 거 아니야? 그럼 세팅하는 시간 뭐 이런 것도 있어야 될 것 같아. 그러니까 지금 보내면 충분하지 않을까요? 썬더버드로 하셨어요? 따로 맥용이 있는데. 그게 나도 되게 잘 통제하게 안 되더라고. 메일이요? 그게 제일 잘 통제하고. 아니 왜 썬더버드를 했냐면. 저번에 대화 내용을 보니까. 썬더버드 관련된 부분에 계속 나와서. 나도 뭐 썬더버드에 뭐가 이슈가 있나 해서. 테스트해봤는데 나는 이상이 없어가지고. 이슈가 아니고. 이게 되게 재밌는 게. 메일을 클라이언트가 다운로드 받잖아요. 그때 이제 방식이 메일을 기존에 만든 거는 통째로 보냈거든요. 이러면 파싱이 안 되는 클라이언트가 있습니다. 근데 기존에 만든 거는 가만히 분석을 해봤더니. 라인 단위로 보내요. 메일을 꺼내서 통으로 보내는 게 아니고. 라인 단위로 잘라서 보내더라고요. 그래서 라인 단위로 잘라서 보냈거든요. 동작해요. 그 차에 몇 차에. 되게 재밌더라고 이게. 왜 그렇게 만드는지 모르겠네. 썬더버드 중에 되게 웃긴 게. 구간모씨가 그랬어. 구간모씨 자리 PC가. 근데 구간모씨 계정을 갖다가. 윈도우 노트북을 하나 만들어서. 거기다가 썬더버드를 깔아가지고 했더니. 정상 동작을 해가지고. PC마다 다른 거야 PC마다. 그러니까 고객도 그럴 가능성이 있다는 거야. 일단 수정이 돼가지고 넣긴 했는데. 이게 라인별로 보내는 거다 보니까. 아무래도 좀. 다운로드 식도가 좀 느려져요. 아무튼 공기를 지금 보내서 미리. 해야 되겠네 그럼. 미리 세팅을 하라고. 세팅을 해놓고 1시에서 2시 타이에. 내려보자고 하자고. 썬더버드 사이트. 썬더버드 사이트. 어디에다. PC.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "result = model.transcribe(audio_filename)\n",
    "transcript = result[\"text\"]\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 요약하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import Template\n",
    "\n",
    "summary_prompt = Template(\"\"\"\n",
    "아래 내용은 사용자의 음성을 텍스트로 변환한 내용입니다.\n",
    "\n",
    "내용을 요약해 주세요.\n",
    "\n",
    "내용: $input\n",
    "요약:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사용자는 머리 스타일에 대한 농담으로 시작해, 업무 관련 내용을 중심으로 세 가지 주제를 다루었습니다. 첫째, 매일 업무 지연 내역 및 소수 관리 내역을 기록하고, 업무 상황을 모니터링하며 문제점을 찾아 코멘트 및 업데이트를 해야 한다고 강조했습니다. 둘째, 업데이트 시 고객에게 공지하는 절차의 중요성을 언급하며, 사전 준비와 정보 제공이 필요하다고 설명했습니다. 마지막으로, 새로운 기술적 이슈와 관련하여 테스트 및 검토가 중요하다고 하며, 팀원들과 소통하여 문제를 해결해 나가야 한다고 강조했습니다. 이 과정에서 문서화와 정보 공유의 필요성도 강조되었습니다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def summary_voice(transcript):\n",
    "  chat_completion = client.chat.completions.create(\n",
    "      model=\"gpt-4o-mini\",\n",
    "      messages=[{\"role\": \"user\", \"content\": summary_prompt.substitute(input=transcript)}],\n",
    "  )\n",
    "\n",
    "  return chat_completion.choices[0].message.content\n",
    "\n",
    "summary_voice(transcript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
