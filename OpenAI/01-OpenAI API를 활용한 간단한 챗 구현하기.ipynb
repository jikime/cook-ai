{"cells":[{"cell_type":"markdown","metadata":{"id":"neQrpe2WXsLD"},"source":["### 환경 설정"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6955,"status":"ok","timestamp":1714894354510,"user":{"displayName":"Gangwoo Kim","userId":"13809575073066285378"},"user_tz":-540},"id":"QWgENrWFYh6l","outputId":"2dcec3e0-004b-417d-8b1b-cfbbedd3f597"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (1.25.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from openai) (4.3.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from openai) (0.26.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from openai) (2.7.1)\n","Requirement already satisfied: sniffio in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from openai) (4.11.0)\n","Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: certifi in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /opt/anaconda3/envs/llm/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install openai python-dotenv"]},{"cell_type":"markdown","metadata":{},"source":[".env 로부터 설정 읽어오기"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"SiTFfW1vpC2Y"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from dotenv import load_dotenv\n","\n","load_dotenv()"]},{"cell_type":"markdown","metadata":{},"source":["openAI API key 가져와서 API 호출"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"am7BNofMdpBk"},"outputs":[],"source":["import os\n","from openai import OpenAI\n","\n","api_key = os.getenv(\"OPENAI_API_KEY\")\n","\n","client = OpenAI(\n","  api_key=api_key,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### 기본적인 Prompt 구조\n","\n","Prompt에는 2가지 종류가 있다.\n","1. 사용자가 LLM한테 실제로 전달하는 Prompt = User Prompt\n","2. User Prompt 이전에 오는 해당 LLM 모델에 적합한 메타 Prompt = System Prompt\n","\n","System Prompt\n","- User Prompt를 전달하기 전에 관련 맥락이나 지침을 설정하는 Prompt\n","  - 페르소나, 어조 등도 설정 할 수 있음\n","- System Prompt 예시\n","  - 출력값 지정 (ex. JSON Formatting)\n","  - 페르소나 및 어조 설정\n","  - 외부 정보 주입\n","  - 모델이 지켜야 할 지침\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"t9wafrI8dckL"},"outputs":[],"source":["query = \"안녕하세요!\"\n","\n","chat_completion = client.chat.completions.create(\n","    messages=[\n","      {\n","        \"role\": \"system\", \n","        \"content\": \"You are a helpful assistant.\"\n","      },\n","      {\n","          \"role\": \"user\",\n","          \"content\": query,\n","      }\n","    ],\n","    max_tokens=300,\n","    temperature=0,\n","    model=\"gpt-3.5-turbo\",\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1714894467728,"user":{"displayName":"Gangwoo Kim","userId":"13809575073066285378"},"user_tz":-540},"id":"8mR1oDYtdzDy","outputId":"f7f79af3-fc89-411a-ef49-1e4822de0a1a"},"outputs":[{"data":{"text/plain":["ChatCompletion(id='chatcmpl-9a3V7EQboVaU0UYaEv5QGKYEPVITE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='안녕하세요! 무엇을 도와드릴까요?', role='assistant', function_call=None, tool_calls=None))], created=1718380293, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=21, prompt_tokens=23, total_tokens=44))"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["chat_completion"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1714894473563,"user":{"displayName":"Gangwoo Kim","userId":"13809575073066285378"},"user_tz":-540},"id":"nXarw3cmdyhn","outputId":"2ebfa003-8e13-44b1-c3e9-a536a84d740a"},"outputs":[{"data":{"text/plain":["'안녕하세요! 무엇을 도와드릴까요?'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["chat_completion.choices[0].message.content"]},{"cell_type":"markdown","metadata":{"id":"iCDDzLyueIXx"},"source":["템플릿을 활용해 프롬프트 만들기"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1714894526029,"user":{"displayName":"Gangwoo Kim","userId":"13809575073066285378"},"user_tz":-540},"id":"oOUyOum5bQ7g","outputId":"b9ad6dbf-88f6-4d17-924d-8cbb46ed2f2c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","다음 사용자의 요청에 답변해주세요.\n","사용자: 안녕하세요!\"\n","답변:\n","\n"]}],"source":["from string import Template\n","\n","prompt_template = Template(f\"\"\"\n","다음 사용자의 요청에 답변해주세요.\n","사용자: {query}\"\n","답변:\n","\"\"\")\n","\n","print(prompt_template.substitute(query=query))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"028jtN2ndJcs"},"outputs":[],"source":["system_prompt = \"\"\"\n","당신은 상담을 해주는 인공지능 에이전트입니다. 친절하고 자세하게 사용자와 대화를 나눠주세요. 필요하면 이모티콘을 사용해도 좋습니다.\n","\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["### 옵션\n","- model: GPT 3.5, GPT-4 버전 별로 선택하실 수 있으며, 보통 더 좋은 성능의 모델일 수록 가격도 그만큼 비싼 편\n","- messages: Prompt, Role, Response/Output\n","- temperature: 높을 수록 동일한 Prompt에도 매번 다르게 이야기하는 경향이 강함. 0.0으로 셋팅 시 같은 답변으로만 대답\n","- max_tokens: \n","  - 모델마다 입력 및 출력 최대 길이가 다르며, 보통 각 모델 소개 페이지에서 찾을 수 있다.\n","  - OpenAI API의 경우 입력 최대 길이 확인: https://platform.openai.com/tokenizer"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1344,"status":"ok","timestamp":1714894599457,"user":{"displayName":"Gangwoo Kim","userId":"13809575073066285378"},"user_tz":-540},"id":"Wu26FAVBYOdl","outputId":"adc9f682-0a8e-4d6e-e2a6-f884cc14785d"},"outputs":[{"data":{"text/plain":["'안녕하세요! 반가워요 😊 어떻게 도와드릴까요?'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["def QnA(query):\n","  prompt = prompt_template.substitute(query=query)\n","  chat_completion = client.chat.completions.create(\n","      messages=[\n","          {\n","            \"role\": \"system\",\n","            \"content\": system_prompt,\n","          },\n","          {\n","              \"role\": \"user\",\n","              \"content\": prompt,\n","          }\n","      ],\n","      model=\"gpt-3.5-turbo\",\n","      max_tokens=300,\n","      temperature=0,\n","  )\n","  return chat_completion.choices[0].message.content\n","\n","QnA(\"안녕하세요! 만나서 반가와요!\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1402,"status":"ok","timestamp":1714894618339,"user":{"displayName":"Gangwoo Kim","userId":"13809575073066285378"},"user_tz":-540},"id":"PxKZG_B3e0Py","outputId":"072466e7-7380-4c52-946a-a2f314429ab7"},"outputs":[{"data":{"text/plain":["'안녕하세요! 반가워요 😊 어떤 일로 저와 대화를 나누고 싶으신가요? 무엇을 도와드릴까요?'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["QnA(\"앞으로 잘 부탁드려요!\")"]},{"cell_type":"markdown","metadata":{},"source":["### Stream 살펴보기\n","- LLM이 문장을 모두 완성하지 않고 각 단어별로 완성되는데로 실시간으로 보여주는 방법"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["이순신 장군은 조선시대의 무신이자 미신으로 유명한 역사적 인물로, 16세기 말부터 17세기 초까지 활약한 조선의 장군입니다. 이순신은 일본의 침략을 막기 위해 전쟁을 치른 무공으로서, 해전에서의 뛰어난 전략과 능력으로 유명합니다. 특히, 명량 해전에서 일본의 강력한 함대를 물리치며 역사상 가장 위대한 해전 중 하나로 꼽히고 있습니다. 이순신은 조선의 국보로 인정받는 인물 중 하나로, 조선사의 영웅으로 여겨지고 있습니다."]}],"source":["stream = client.chat.completions.create(\n","    model='gpt-3.5-turbo',\n","    messages=[{'role': 'user', 'content': '이순신 장군은 어떤 분인가요?'}],\n","    temperature=0.0,\n","    stream=True\n",")\n","\n","for chunk in stream:\n","  if chunk.choices[0].delta.content is not None:\n","    print(chunk.choices[0].delta.content, end='')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"llm","language":"python","name":"llm"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
